{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from metrics import CorefEvaluator\n",
    "from document import Document\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ClEval import ClEval, print_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_timestamp():\n",
    "    return str(datetime.timestamp(datetime.now())).split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1590497499'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_timestamp()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Desired functionality...\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        for line in dataset:\n",
    "            doc_key = None\n",
    "            gold_clusters = None\n",
    "            tokens = None\n",
    "            \n",
    "            merged = ' '.join(tokens)\n",
    "            predicted_clusters = model.predict(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"\n",
    "Microsoft (NASDAQ:MSFT) was once considered a mature tech stock that was owned for stability and income instead of growth. But over the past five years, Microsoft stock rallied roughly 300% as a visionary CEO turned its business upside down.\n",
    "\n",
    "Satya Nadella, who succeeded Steve Ballmer in 2014, reduced Microsoft's dependence on sales of Windows and Office licenses and expanded its ecosystem with a \"mobile first, cloud first\" mantra. Nadella ditched the company's Windows Phone and smartphone ambitions, launched mobile versions of its apps on iOS and Android, and aggressively expanded its cloud services.\n",
    "\n",
    "That transformation initially throttled earnings growth, but it paid off as the commercial cloud business -- which included Office 365, Dynamics 365, and Azure -- became its new growth engine. Microsoft also expanded its Surface and Xbox businesses to maintain a healthy presence in the PC and gaming markets, respectively.\n",
    "\n",
    "Those strengths buoyed Microsoft's results throughout the COVID-19 crisis, and its stock has risen nearly 11% year to date even as the S&P 500 slipped over 12%. But looking further ahead, will Microsoft continue to outperform the market?\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".highlight {\n",
       "  border: 2px solid;\n",
       "  color: #232323;\n",
       "  margin: 4px 6px 4px 3px;\n",
       "  vertical-align: middle;\n",
       "  box-shadow: 2px 4px 20px rgba(0,0,0,0.1);\n",
       "  position: relative;\n",
       "  cursor: default;\n",
       "  min-width: 26px;\n",
       "  line-height: 22px;\n",
       "  display: inline-flex;\n",
       "}\n",
       "\n",
       ".highlight:last-child {\n",
       "  margin-right: 4px;\n",
       "}\n",
       "\n",
       ".highlight:first-child {\n",
       "  margin-left: 0;\n",
       "}\n",
       "\n",
       ".highlight,\n",
       ".highlight span {\n",
       "  transition: background-color .1s ease,\n",
       "              color .1s ease,\n",
       "              box-shadow .1s ease,\n",
       "              opacity .1s ease;\n",
       "}\n",
       "\n",
       ".highlight.short-text {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".highlight__label {\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  padding: 0 8px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "}\n",
       "\n",
       ".highlight__label strong,\n",
       ".highlight__label span.highlight__label__secondary-label {\n",
       "  display: block;\n",
       "  font-size: 11px;\n",
       "  color: #fff;\n",
       "  -webkit-font-smoothing: subpixel-antialiased;\n",
       "  letter-spacing: 0.1em;\n",
       "}\n",
       "\n",
       ".highlight__label strong {\n",
       "  text-transform: uppercase;\n",
       "}\n",
       "\n",
       ".highlight__label span.highlight__label__secondary-label {\n",
       "  opacity: .75;\n",
       "  padding-left: 6px;\n",
       "}\n",
       "\n",
       ".highlight__content {\n",
       "  flex-wrap: wrap;\n",
       "  align-items: center;\n",
       "  padding: 2px 2px 2px 6px;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight-container.highlight-container--bottom-labels .highlight.bottom {\n",
       "  margin-top: 6px;\n",
       "}\n",
       "\n",
       ".highlight.bottom {\n",
       "  display: block;\n",
       "  white-space: normal;\n",
       "}\n",
       "\n",
       ".highlight.bottom .highlight__content:after {\n",
       "  content: \" \";\n",
       "  padding-right: 3px;\n",
       "}\n",
       "\n",
       ".highlight.bottom .highlight__label {\n",
       "  line-height: 14px;\n",
       "  padding-top: 1px;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.top {\n",
       "  flex-direction: column;\n",
       "  white-space: normal;\n",
       "}\n",
       "\n",
       ".highlight.top .highlight__label {\n",
       "  min-height: 22px;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.active,\n",
       ".highlight.active span {\n",
       "  color: #fff;\n",
       "}\n",
       "\n",
       ".highlight.active .highlight:not(.active) span {\n",
       "  color: #232323;\n",
       "}\n",
       "\n",
       ".highlight.clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight.clickable.clickable.selected {\n",
       "  cursor: default;\n",
       "}\n",
       "\n",
       ".highlight.clickable.clicking {\n",
       "  opacity: 0.66;\n",
       "  transition-duration: 0s;\n",
       "}\n",
       "\n",
       ".clicking .highlight,\n",
       ".clicking .highlight span,\n",
       ".clicking .highlight:before,\n",
       ".clicking .highlight:after {\n",
       "  transition-duration: 0s;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.gray {\n",
       "  background: #f2f4f6;\n",
       "}\n",
       "\n",
       ".highlight.gray,\n",
       ".highlight-arrow--gray .highlight-arrow__triangle {\n",
       "  border-color: #a0aab5;\n",
       "}\n",
       "\n",
       ".highlight.gray .highlight__label,\n",
       ".highlight-arrow--gray .highlight-arrow__stalk,\n",
       ".highlight.gray .highlight__button .highlight__button__body {\n",
       "  background-color: #a0aab5;\n",
       "}\n",
       "\n",
       ".highlight.gray.active {\n",
       "  background: #a0aab5;\n",
       "}\n",
       "\n",
       ".highlight.gray.active .highlight__label {\n",
       "  background-color: #aab3bd;\n",
       "}\n",
       "\n",
       ".highlight.gray .highlight__button svg {\n",
       "  fill: #a0aab5;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       ".highlight.blue {\n",
       "  background: #edf4fa;\n",
       "}\n",
       "\n",
       ".highlight.blue,\n",
       ".highlight-arrow--blue .highlight-arrow__triangle {\n",
       "  border-color: #4db1f7;\n",
       "}\n",
       "\n",
       ".highlight.blue > .highlight__label,\n",
       ".highlight-arrow--blue .highlight-arrow__stalk,\n",
       ".highlight.blue .highlight__button .highlight__button__body {\n",
       "  background-color: #4db1f7;\n",
       "}\n",
       "\n",
       ".highlight.blue.active {\n",
       "  background: #4db1f7;\n",
       "}\n",
       "\n",
       ".highlight.blue.active > .highlight__label {\n",
       "  background-color: #5fb9f8;\n",
       "}\n",
       "\n",
       ".highlight.blue .highlight__button svg {\n",
       "  fill: #4db1f7;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.green {\n",
       "  background: #f1f4f1;\n",
       "}\n",
       "\n",
       ".highlight.green,\n",
       ".highlight-arrow--green .highlight-arrow__triangle {\n",
       "  border-color: #90ac4e;\n",
       "}\n",
       "\n",
       ".highlight.green > .highlight__label,\n",
       ".highlight-arrow--green .highlight-arrow__stalk,\n",
       ".highlight.green .highlight__button .highlight__button__body {\n",
       "  background-color: #90ac4e;\n",
       "}\n",
       "\n",
       ".highlight.green.active {\n",
       "  background: #90ac4e;\n",
       "}\n",
       "\n",
       ".highlight.green.active > .highlight__label {\n",
       "  background-color: #9bb460;\n",
       "}\n",
       "\n",
       ".highlight.green .highlight__button svg {\n",
       "  fill: #90ac4e;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.pink {\n",
       "  background: #f4f1f4;\n",
       "}\n",
       "\n",
       ".highlight.pink,\n",
       ".highlight-arrow--pink .highlight-arrow__triangle {\n",
       "  border-color: #ce6587;\n",
       "}\n",
       "\n",
       ".highlight.pink > .highlight__label,\n",
       ".highlight-arrow--pink .highlight-arrow__stalk,\n",
       ".highlight.pink .highlight__button .highlight__button__body {\n",
       "  background-color: #ce6587;\n",
       "}\n",
       "\n",
       ".highlight.pink.active {\n",
       "  background: #ce6587;\n",
       "}\n",
       "\n",
       ".highlight.pink.active > .highlight__label {\n",
       "  background-color: #d37593;\n",
       "}\n",
       "\n",
       ".highlight.pink .highlight__button svg {\n",
       "  fill: #ce6587;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.orange {\n",
       "  background: #f2f4f4;\n",
       "}\n",
       "\n",
       ".highlight.orange,\n",
       ".highlight-arrow--orange .highlight-arrow__triangle {\n",
       "  border-color: #dd9e3e;\n",
       "}\n",
       "\n",
       ".highlight.orange > .highlight__label,\n",
       ".highlight-arrow--orange .highlight-arrow__stalk,\n",
       ".highlight.orange .highlight__button .highlight__button__body {\n",
       "  background-color: #dd9e3e;\n",
       "}\n",
       "\n",
       ".highlight.orange.active {\n",
       "  background: #dd9e3e;\n",
       "}\n",
       "\n",
       ".highlight.orange.active > .highlight__label {\n",
       "  background-color: #e0a852;\n",
       "}\n",
       "\n",
       ".highlight.orange .highlight__button svg {\n",
       "  fill: #dd9e3e;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.purple {\n",
       "  background: #f1f0f7;\n",
       "}\n",
       "\n",
       ".highlight.purple,\n",
       ".highlight-arrow--purple .highlight-arrow__triangle {\n",
       "  border-color: #9a5eba;\n",
       "}\n",
       "\n",
       ".highlight.purple > .highlight__label,\n",
       ".highlight-arrow--purple .highlight-arrow__stalk,\n",
       ".highlight.purple .highlight__button .highlight__button__body {\n",
       "  background-color: #9a5eba;\n",
       "}\n",
       "\n",
       ".highlight.purple.active {\n",
       "  background: #9a5eba;\n",
       "}\n",
       "\n",
       ".highlight.purple.active > .highlight__label {\n",
       "  background-color: #a46ec1;\n",
       "}\n",
       "\n",
       ".highlight.purple .highlight__button svg {\n",
       "  fill: #9a5eba;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.teal {\n",
       "  background: #eef4f6;\n",
       "}\n",
       "\n",
       ".highlight.teal,\n",
       ".highlight-arrow--teal .highlight-arrow__triangle {\n",
       "  border-color: #5bb1ad;\n",
       "}\n",
       "\n",
       ".highlight.teal > .highlight__label,\n",
       ".highlight-arrow--teal .highlight-arrow__stalk,\n",
       ".highlight.teal .highlight__button .highlight__button__body {\n",
       "  background-color: #5bb1ad;\n",
       "}\n",
       "\n",
       ".highlight.teal.active {\n",
       "  background: #5bb1ad;\n",
       "}\n",
       "\n",
       ".highlight.teal.active > .highlight__label {\n",
       "  background-color: #6cb9b5;\n",
       "}\n",
       "\n",
       ".highlight.teal .highlight__button svg {\n",
       "  fill: #5bb1ad;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.tan {\n",
       "  background: #f2f4f4;\n",
       "}\n",
       "\n",
       ".highlight.tan,\n",
       ".highlight-arrow--tan .highlight-arrow__triangle {\n",
       "  border-color: #b0a481;\n",
       "}\n",
       "\n",
       ".highlight.tan > .highlight__label,\n",
       ".highlight-arrow--tan .highlight-arrow__stalk,\n",
       ".highlight.tan .highlight__button .highlight__button__body {\n",
       "  background-color: #b0a481;\n",
       "}\n",
       "\n",
       ".highlight.tan.active {\n",
       "  background: #b0a481;\n",
       "}\n",
       "\n",
       ".highlight.tan.active > .highlight__label {\n",
       "  background-color: #b8ad8e;\n",
       "}\n",
       "\n",
       ".highlight.tan .highlight__button svg {\n",
       "  fill: #b0a481;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.red {\n",
       "  background: #f5eef0;\n",
       "}\n",
       "\n",
       ".highlight.red,\n",
       ".highlight-arrow--red .highlight-arrow__triangle {\n",
       "  border-color: #df3838;\n",
       "}\n",
       "\n",
       ".highlight.red > .highlight__label,\n",
       ".highlight-arrow--red .highlight-arrow__stalk,\n",
       ".highlight.red .highlight__button .highlight__button__body {\n",
       "  background-color: #df3838;\n",
       "}\n",
       "\n",
       ".highlight.red.active {\n",
       "  background: #df3838;\n",
       "}\n",
       "\n",
       ".highlight.red.active > .highlight__label {\n",
       "  background-color: #e24c4c;\n",
       "}\n",
       "\n",
       ".highlight.red .highlight__button svg {\n",
       "  fill: #df3838;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.cobalt {\n",
       "  background: #eef0f5;\n",
       "}\n",
       "\n",
       ".highlight.cobalt,\n",
       ".highlight-arrow--cobalt .highlight-arrow__triangle {\n",
       "  border-color: #5f5b97;\n",
       "}\n",
       "\n",
       ".highlight.cobalt > .highlight__label,\n",
       ".highlight-arrow--cobalt .highlight-arrow__stalk,\n",
       ".highlight.cobalt .highlight__button .highlight__button__body {\n",
       "  background-color: #5f5b97;\n",
       "}\n",
       "\n",
       ".highlight.cobalt.active {\n",
       "  background: #5f5b97;\n",
       "}\n",
       "\n",
       ".highlight.cobalt.active > .highlight__label {\n",
       "  background-color: #6f6ca2;\n",
       "}\n",
       "\n",
       ".highlight.cobalt .highlight__button svg {\n",
       "  fill: #5f5b97;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.brown {\n",
       "  background: #f2f4f6;\n",
       "}\n",
       "\n",
       ".highlight.brown,\n",
       ".highlight-arrow--brown .highlight-arrow__triangle {\n",
       "  border-color: #6a4e3d;\n",
       "}\n",
       "\n",
       ".highlight.brown > .highlight__label,\n",
       ".highlight-arrow--brown .highlight-arrow__stalk,\n",
       ".highlight.brown .highlight__button .highlight__button__body {\n",
       "  background-color: #6a4e3d;\n",
       "}\n",
       "\n",
       ".highlight.brown.active {\n",
       "  background: #6a4e3d;\n",
       "}\n",
       "\n",
       ".highlight.brown.active > .highlight__label {\n",
       "  background-color: #796051;\n",
       "}\n",
       "\n",
       ".highlight.brown .highlight__button svg {\n",
       "  fill: #6a4e3d;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.slate {\n",
       "  background: #eceff1;\n",
       "}\n",
       "\n",
       ".highlight.slate,\n",
       ".highlight-arrow--slate .highlight-arrow__triangle {\n",
       "  border-color: #3b4247;\n",
       "}\n",
       "\n",
       ".highlight.slate > .highlight__label,\n",
       ".highlight-arrow--slate .highlight-arrow__stalk,\n",
       ".highlight.slate .highlight__button .highlight__button__body {\n",
       "  background-color: #3b4247;\n",
       "}\n",
       "\n",
       ".highlight.slate.active {\n",
       "  background: #3b4247;\n",
       "}\n",
       "\n",
       ".highlight.slate.active > .highlight__label {\n",
       "  background-color: #4f555a;\n",
       "}\n",
       "\n",
       ".highlight.slate .highlight__button svg {\n",
       "  fill: #3b4247;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia {\n",
       "  background: #f5f1f9;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia,\n",
       ".highlight-arrow--fuchsia .highlight-arrow__triangle {\n",
       "  border-color: #e875e8;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia > .highlight__label,\n",
       ".highlight-arrow--fuchsia .highlight-arrow__stalk,\n",
       ".highlight.fuchsia .highlight__button .highlight__button__body {\n",
       "  background-color: #e875e8;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia.active {\n",
       "  background: #e875e8;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia.active > .highlight__label {\n",
       "  background-color: #ea83ea;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia .highlight__button svg {\n",
       "  fill: #e875e8;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight__tooltip {\n",
       "  display: block;\n",
       "  position: absolute;\n",
       "  box-shadow: 0 0 30px rgba(0,0,0,.2);\n",
       "  border-radius: 6px;\n",
       "  background: rgba(70,70,70,.9);\n",
       "  padding: 4px 9px 5px 9px;\n",
       "  opacity: 0;\n",
       "  z-index: -9;\n",
       "  left: 50%;\n",
       "  top: 100%;\n",
       "  margin-top: 10px;\n",
       "  font-size: 14px;\n",
       "  color: #fff;\n",
       "  transform: translate(-50%, -6px);\n",
       "  transition: opacity .2s ease,\n",
       "              z-index .2s ease,\n",
       "              transform .2s ease .3s;\n",
       "  font-weight: bold;\n",
       "  white-space: nowrap;\n",
       "  user-select: none;\n",
       "  cursor: default;\n",
       "}\n",
       "\n",
       ".highlight__tooltip:before {\n",
       "  display: block;\n",
       "  position: absolute;\n",
       "  left: 50%;\n",
       "  top: 0;\n",
       "  margin-top: -6px;\n",
       "  margin-left: -6px;\n",
       "  content: \"\";\n",
       "  width: 0;\n",
       "  height: 0;\n",
       "  border-style: solid;\n",
       "  border-width: 0 6px 6px 6px;\n",
       "  border-color: transparent transparent rgba(70,70,70,.9) transparent;\n",
       "}\n",
       "\n",
       ".highlight:hover .highlight__tooltip {\n",
       "  z-index: 9;\n",
       "  opacity: 1;\n",
       "  transform: translate(-50%, 0);\n",
       "  transition-delay: 0s;\n",
       "}\n",
       "\n",
       ".highlight__tooltip:hover {\n",
       "  z-index: -9 !important;\n",
       "}\n",
       "\n",
       ".highlight-container {\n",
       "  line-height: 42px !important;\n",
       "  align-items: center;\n",
       "  display: flex;\n",
       "  flex-wrap: wrap;\n",
       "  white-space: pre;\n",
       "  cursor: default;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight-container.highlight-container--bottom-labels {\n",
       "  padding: 10px 1.125em;\n",
       "  align-items: flex-start;\n",
       "}\n",
       "\n",
       ".highlight-container.highlight-container--diagram {\n",
       "  align-items: flex-start;\n",
       "}\n",
       "\n",
       ".highlight-container.highlight-container--diagram.passage.model__content__summary {\n",
       "  background: transparent;\n",
       "  align-items: stretch;\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    \n",
       "function handleHighlightMouseOver(el) {\n",
       "    $('[id='+el.getAttribute('id')+']').addClass('active');\n",
       "  }\n",
       "\n",
       "function handleHighlightMouseOut(el) {\n",
       "    $('[id='+el.getAttribute('id')+']').removeClass('active');\n",
       "}\n",
       "  \n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from VISUALIZATION import highlighter as viz\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(open('VISUALIZATION/highlighter/highlight.css').read()))\n",
    "display(HTML(open('VISUALIZATION/highlighter/highlight.js').read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup\n",
    "- Stanford CoreNLP Deterministic\n",
    "- NeuralCoref\n",
    "- SpanBERT Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MODEL_WRAPPERS.Corenlp import CoreNLP\n",
    "corenlp = CoreNLP(ram=\"8G\", viz=viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MODEL_WRAPPERS.Neuralcoref import Coref\n",
    "params = {\n",
    "    \"greed\": 0.50,\n",
    "    \"max_dist\": 100,\n",
    "    \"max_dist_match\": 500\n",
    "}\n",
    "neuralcoref = Coref(params, spacy_size=\"lg\", viz=viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating ../../pretrained/allen-spanbert-large/config.json as plain json\n",
      "Did not use initialization regex that was passed: _context_layer._module.weight_ih.*\n",
      "Did not use initialization regex that was passed: _context_layer._module.weight_hh.*\n"
     ]
    }
   ],
   "source": [
    "from MODEL_WRAPPERS.Spanbert import SpanBert\n",
    "spanbert = SpanBert(viz=viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [corenlp, neuralcoref, spanbert]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch prediction, testing iterating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print(\"Prediction with {}\".format(str(model.__class__)))\n",
    "    start = timeit.default_timer()\n",
    "    clusters = predict(model, txt)\n",
    "    #show(model)\n",
    "    stop = timeit.default_timer()\n",
    "    print('Time: ', stop - start)  \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Tollef\\\\Documents\\\\GitHub\\\\masterNEW\\\\REPO\\\\coreference_data\\\\dev_data\\\\gum.coreflite',\n",
       " 'C:\\\\Users\\\\Tollef\\\\Documents\\\\GitHub\\\\masterNEW\\\\REPO\\\\coreference_data\\\\dev_data\\\\litbank.coreflite',\n",
       " 'C:\\\\Users\\\\Tollef\\\\Documents\\\\GitHub\\\\masterNEW\\\\REPO\\\\coreference_data\\\\dev_data\\\\ontonotes_dev.coreflite',\n",
       " 'C:\\\\Users\\\\Tollef\\\\Documents\\\\GitHub\\\\masterNEW\\\\REPO\\\\coreference_data\\\\dev_data\\\\preco_dev.coreflite']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(os.path.dirname(os.getcwd()), \"coreference_data\")\n",
    "\n",
    "dev_path = os.path.join(data_path, \"dev_data\")\n",
    "\n",
    "datasets = [os.path.join(dev_path, f) for f in os.listdir(dev_path)]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "news_path = os.path.join(data_path, \"news_data\")\n",
    "datasets = [os.path.join(news_path, f) for f in os.listdir(news_path)]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# out of domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdomain = os.path.join(data_path, \"out_of_domain\")\n",
    "datasets = [os.path.join(outdomain, f) for f in os.listdir(outdomain)]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preco large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preco_large = os.path.join(data_path, \"big_files\", \"preco.coreflite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gum, lit, onto, prec = datasets\n",
    "#model = corenlp # corenlp, neuralcoref, spanbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "onto_test = os.path.join(data_path, \"ontonotes_test.coreflite\")\n",
    "gum_news = os.path.join(data_path, \"gum_news.coreflite\")\n",
    "gum_no_news = os.path.join(data_path, \"gum_no_news.coreflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                         | 0/36620 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                              | 1/36620 [00:05<52:57:54,  5.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preco - train_00001. 1/36620\t\tconll: 0.33550305626373994\t lea: 0.2412347904461469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                              | 2/36620 [00:09<51:29:56,  5.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preco - train_00002. 2/36620\t\tconll: 0.34829824040137186\t lea: 0.2955240100522991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                              | 3/36620 [00:13<45:34:07,  4.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preco - train_00003. 3/36620\t\tconll: 0.45535653623192\t lea: 0.3699115044247787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                              | 4/36620 [00:17<45:29:38,  4.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preco - train_00004. 4/36620\t\tconll: 0.5161847031593781\t lea: 0.47708119218910583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                              | 5/36620 [00:27<61:10:24,  6.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preco - train_00005. 5/36620\t\tconll: 0.4846170761839579\t lea: 0.40737763587845255\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-77ce29bb2798>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m                         \u001b[0mtokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                         \u001b[0madjust_wrong_offsets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                         no_singletons=True)\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;31m#cleval.compare()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mconll_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlea_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\masterNEW\\REPO\\coreference\\ClEval.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(self, jsonobject, tokens, adjust_wrong_offsets, no_singletons)\u001b[0m\n\u001b[0;32m    117\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0madjust_wrong_offsets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\masterNEW\\REPO\\coreference\\ClEval.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\masterNEW\\REPO\\coreference\\MODEL_WRAPPERS\\Spanbert.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"clusters\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\allennlp_models\\coref\\coref_predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, document)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mrepresentation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mcoreference\u001b[0m \u001b[0mclusters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"document\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_tokenized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenized_document\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\allennlp\\predictors\\predictor.py\u001b[0m in \u001b[0;36mpredict_json\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0minstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_json_to_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjson_to_labeled_instances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInstance\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\allennlp\\predictors\\predictor.py\u001b[0m in \u001b[0;36mpredict_instance\u001b[1;34m(self, instance)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mInstance\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_on_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\allennlp\\models\\model.py\u001b[0m in \u001b[0;36mforward_on_instance\u001b[1;34m(self, instance)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensors\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minto\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mremove\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mdimension\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \"\"\"\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_on_instances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward_on_instances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInstance\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\allennlp\\models\\model.py\u001b[0m in \u001b[0;36mforward_on_instances\u001b[1;34m(self, instances)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_instances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mmodel_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_output_human_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             instance_separated_output: List[Dict[str, numpy.ndarray]] = [\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\allennlp_models\\coref\\coref_model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, text, spans, span_labels, metadata)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m    179\u001b[0m         \u001b[1;31m# Shape: (batch_size, document_length, embedding_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mtext_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lexical_dropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_text_field_embedder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\allennlp\\modules\\text_field_embedders\\basic_text_field_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, text_field_input, num_wrapping_dims, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[1;31m# If there are multiple tensor arguments, we have to require matching names from the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;31m# TokenIndexer.  I don't think there's an easy way around that.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mtoken_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mforward_params_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtoken_vectors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[1;31m# To handle some very rare use cases, we allow the return value of the embedder to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\allennlp\\modules\\token_embedders\\pretrained_transformer_mismatched_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, token_ids, mask, offsets, wordpiece_mask, type_ids, segment_concat_mask)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Shape: [batch_size, num_wordpieces, embedding_size].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         embeddings = self._matched_embedder(\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mtoken_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwordpiece_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegment_concat_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msegment_concat_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         )\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\allennlp\\modules\\token_embedders\\pretrained_transformer_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, token_ids, mask, type_ids, segment_concat_mask)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype_ids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_type_ids\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfold_long_sequences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m         )\n\u001b[0;32m    792\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m             layer_outputs = layer_module(\n\u001b[1;32m--> 407\u001b[1;33m                 \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m             )\n\u001b[0;32m    409\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcross_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# add cross attentions if we output attention weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tollef\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1372\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1373\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#dataset = onto_test\n",
    "#model = corenlp\n",
    "#outliers = []\n",
    "dataset = preco_large\n",
    "model = spanbert\n",
    "#GUM_VERSION_2 = [\"GUM_interview_ants.conll\", \"GUM_interview_brotherhood.conll\", \"GUM_interview_cocktail.conll\", \"GUM_interview_cyclone.conll\", \"GUM_interview_daly.conll\", \"GUM_interview_dungeon.conll\", \"GUM_interview_gaming.conll\", \"GUM_interview_herrick.conll\", \"GUM_interview_hill.conll\", \"GUM_interview_libertarian.conll\", \"GUM_interview_licen.conll\", \"GUM_interview_mckenzie.conll\", \"GUM_interview_messina.conll\", \"GUM_interview_peres.conll\", \"GUM_news_asylum.conll\", \"GUM_news_crane.conll\", \"GUM_news_defector.conll\", \"GUM_news_flag.conll\", \"GUM_news_hackers.conll\", \"GUM_news_ie9.conll\", \"GUM_news_imprisoned.conll\", \"GUM_news_korea.conll\", \"GUM_news_nasa.conll\", \"GUM_news_sensitive.conll\", \"GUM_news_stampede.conll\", \"GUM_news_taxes.conll\", \"GUM_news_warhol.conll\", \"GUM_news_warming.conll\", \"GUM_news_worship.conll\", \"GUM_voyage_athens.conll\", \"GUM_voyage_chatham.conll\", \"GUM_voyage_cleveland.conll\", \"GUM_voyage_coron.conll\", \"GUM_voyage_cuba.conll\", \"GUM_voyage_fortlee.conll\", \"GUM_voyage_merida.conll\", \"GUM_voyage_oakland.conll\", \"GUM_voyage_thailand.conll\", \"GUM_voyage_vavau.conll\", \"GUM_voyage_york.conll\", \"GUM_whow_arrogant.conll\", \"GUM_whow_basil.conll\", \"GUM_whow_cactus.conll\", \"GUM_whow_chicken.conll\", \"GUM_whow_cupcakes.conll\", \"GUM_whow_flirt.conll\", \"GUM_whow_glowstick.conll\", \"GUM_whow_joke.conll\", \"GUM_whow_languages.conll\", \"GUM_whow_overalls.conll\", \"GUM_whow_packing.conll\", \"GUM_whow_parachute.conll\", \"GUM_whow_quidditch.conll\", \"GUM_whow_skittles.conll\"]\n",
    "with open(dataset, \"r\", encoding=\"utf8\") as data:\n",
    "    modelstr = str(model.__class__).split(\".\")[1]\n",
    "    datastr = dataset.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    filename = \"{}_{}_{}.txt\".format(modelstr, datastr, get_timestamp())\n",
    "    filepath = os.path.join(os.getcwd(), \"logs\", filename)\n",
    "\n",
    "    all_docs = data.readlines()\n",
    "    #print(\"Total of {} docs\".format(len(all_docs)))\n",
    "\n",
    "    FILES_TO_COUNT = len(all_docs)\n",
    "\n",
    "    dataset_scorer = CorefEvaluator()\n",
    "\n",
    "    #for i, doc in tqdm(enumerate(all_docs)):\n",
    "    for i in tqdm(range(len(all_docs))):\n",
    "        doc = all_docs[i]\n",
    "        doc = json.loads(doc)\n",
    "        docname = doc[\"doc_key\"]\n",
    "\n",
    "        cleval = ClEval(model=model)\n",
    "        cleval.pipeline(doc,\n",
    "                        tokens=False,\n",
    "                        adjust_wrong_offsets=True,\n",
    "                        no_singletons=True)\n",
    "        #cleval.compare()\n",
    "        conll_score, lea_score = cleval.show_score(verbose=False)\n",
    "\n",
    "        print(\"{} - {}. {}/{}\\t\\tconll: {}\\t lea: {}\".format(\n",
    "            datastr, docname, i+1, len(all_docs),\n",
    "            conll_score, lea_score\n",
    "        ))\n",
    "        #cleval.show_score(verbose=True)\n",
    "        #print(\"p/r/f\", cleval.scorer.get_prf_conll())\n",
    "        dataset_scorer.update(cleval.doc)\n",
    "\n",
    "        #if i == 19:\n",
    "        #    break\n",
    "\n",
    "    dataset_scorer.detailed_score(modelstr, datastr)\n",
    "    print(dataset_scorer.get_conll())\n",
    "    #cleval.write_scores_to_file(modelstr, datastr)\n",
    "    #cleval.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = cleval.gold_clusters\n",
    "gs = cleval.gold_clusters_no_singletons\n",
    "viz.raw_render(cleval.tokens, g)\n",
    "viz.raw_render(cleval.tokens, gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tokens = zip(cleval.tokens, cleval.pred_tokens())\n",
    "for c in combined_tokens:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pflat = flatten(cleval.pred_clusters)\n",
    "cl = sorted(pflat, key=lambda x: x[0])\n",
    "for c in cl:\n",
    "    print(c, cleval.tokens[c[0]-1:c[1]+1])\n",
    "    print(c, cleval.pred_tokens()[c[0]:c[1]+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pflat = flatten(cleval.gold_clusters)\n",
    "cl = sorted(pflat, key=lambda x: x[0])\n",
    "for c in cl:\n",
    "    print(c, cleval.tokens[c[0]:c[1]+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens = cleval.tokens\n",
    "clusters = cleval.pred_clusters\n",
    "for clust in clusters:\n",
    "    for mention in clust:\n",
    "        print(mention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "viz.raw_render(cleval.tokens, cleval.gold_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spandoc = cleval.model.doc\n",
    "spandoc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleval.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(spandoc[\"document\"])\n",
    "spandoc[\"document\"][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spandoc[\"antecedent_indices\"][0:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
